{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqWH0E_RcwVq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# simulate the user profiles\n",
        "users_data = {\n",
        "    'user_id': [1, 2, 3, 4, 5],\n",
        "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
        "    'skills': ['Python, Data Science', 'Java, Spring', 'JavaScript, React', 'Python, Machine Learning', 'Java, AWS'],\n",
        "    'location': ['New York', 'San Francisco', 'London', 'Toronto', 'Berlin']\n",
        "}\n",
        "\n",
        "# Simulated job postings data\n",
        "jobs_data = {\n",
        "    'job_id': [101, 102, 103, 104, 105],\n",
        "    'title': ['Data Scientist', 'Java Developer', 'Frontend Engineer', 'ML Engineer', 'AWS Architect'],\n",
        "    'skills_required': ['Python, Machine Learning', 'Java, Spring', 'JavaScript, HTML', 'Python, Deep Learning', 'AWS, Cloud'],\n",
        "    'location': ['New York', 'San Francisco', 'London', 'Toronto', 'Berlin']\n",
        "}\n",
        "\n",
        "# Simulated user-job interaction data\n",
        "interactions_data = {\n",
        "    'user_id': [1, 2, 3, 4, 5, 1, 2, 3, 4, 5],\n",
        "    'job_id': [101, 102, 103, 104, 105, 102, 101, 105, 103, 104],\n",
        "    'applied': [1, 1, 0, 0, 1, 0, 1, 0, 1, 0]\n",
        "}"
      ],
      "metadata": {
        "id": "KlfRfIsDdB3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert these into data frames\n",
        "users_df = pd.DataFrame(users_data)\n",
        "jobs_df = pd.DataFrame(jobs_data)\n",
        "interactions_df = pd.DataFrame(interactions_data)"
      ],
      "metadata": {
        "id": "Oyv-hw-idTRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the data\n",
        "print(\"Users Data:\")\n",
        "print(users_df)\n",
        "print(\"\\nJobs Data:\")\n",
        "print(jobs_df)\n",
        "print(\"\\nInteractions Data:\")\n",
        "print(interactions_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L05_TFoQdj8s",
        "outputId": "ef012a2a-a8c2-4b04-e121-0c9a040ae544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Users Data:\n",
            "   user_id     name                    skills       location\n",
            "0        1    Alice      Python, Data Science       New York\n",
            "1        2      Bob              Java, Spring  San Francisco\n",
            "2        3  Charlie         JavaScript, React         London\n",
            "3        4    David  Python, Machine Learning        Toronto\n",
            "4        5      Eve                 Java, AWS         Berlin\n",
            "\n",
            "Jobs Data:\n",
            "   job_id              title           skills_required       location\n",
            "0     101     Data Scientist  Python, Machine Learning       New York\n",
            "1     102     Java Developer              Java, Spring  San Francisco\n",
            "2     103  Frontend Engineer          JavaScript, HTML         London\n",
            "3     104        ML Engineer     Python, Deep Learning        Toronto\n",
            "4     105      AWS Architect                AWS, Cloud         Berlin\n",
            "\n",
            "Interactions Data:\n",
            "   user_id  job_id  applied\n",
            "0        1     101        1\n",
            "1        2     102        1\n",
            "2        3     103        0\n",
            "3        4     104        0\n",
            "4        5     105        1\n",
            "5        1     102        0\n",
            "6        2     101        1\n",
            "7        3     105        0\n",
            "8        4     103        1\n",
            "9        5     104        0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize CountVectorizer for skills\n",
        "skill_vectorizer = CountVectorizer(tokenizer=lambda x: x.split(', '))\n",
        "user_skills_matrix = skill_vectorizer.fit_transform(users_df['skills']).toarray()\n",
        "job_skills_matrix = skill_vectorizer.transform(jobs_df['skills_required']).toarray()\n",
        "\n",
        "# Label encode locations\n",
        "location_encoder = LabelEncoder()\n",
        "users_df['location_encoded'] = location_encoder.fit_transform(users_df['location'])\n",
        "jobs_df['location_encoded'] = location_encoder.transform(jobs_df['location'])\n",
        "\n",
        "# Merge skills and locations into user/job profiles\n",
        "user_profiles = np.hstack([user_skills_matrix, users_df['location_encoded'].values.reshape(-1, 1)])\n",
        "job_profiles = np.hstack([job_skills_matrix, jobs_df['location_encoded'].values.reshape(-1, 1)])\n",
        "\n",
        "print(\"User Profiles:\")\n",
        "print(user_profiles)\n",
        "\n",
        "print(\"\\nJob Profiles:\")\n",
        "print(job_profiles)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VE_YEcYidmum",
        "outputId": "c0332f9f-e555-4139-ba43-35701f2aef95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User Profiles:\n",
            "[[0 1 0 0 0 1 0 0 2]\n",
            " [0 0 1 0 0 0 0 1 3]\n",
            " [0 0 0 1 0 0 1 0 1]\n",
            " [0 0 0 0 1 1 0 0 4]\n",
            " [1 0 1 0 0 0 0 0 0]]\n",
            "\n",
            "Job Profiles:\n",
            "[[0 0 0 0 1 1 0 0 2]\n",
            " [0 0 1 0 0 0 0 1 3]\n",
            " [0 0 0 1 0 0 0 0 1]\n",
            " [0 0 0 0 0 1 0 0 4]\n",
            " [1 0 0 0 0 0 0 0 0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for _, row in interactions_df.iterrows():\n",
        "  user_id = row['user_id']\n",
        "  job_id = row['job_id']\n",
        "  applied = row['applied']\n",
        "\n",
        "  user_profile = user_profiles[user_id -1] # user profile vector\n",
        "  job_profile = job_profiles[job_id-101] # job profile vector\n",
        "\n",
        "  X.append(np.concatenate((user_profile, job_profile)))\n",
        "  y.append(applied)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# split the data into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "yjTiQSN7f8Ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# simple feedforward neural network using TensorFlow to predict whether a user will apply for a job\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(layers.Dense(128, activation = 'relu', input_shape = (X_train.shape[1],)))\n",
        "model.add(layers.Dropout(0.3))\n",
        "\n",
        "model.add(layers.Dense(64, activation = 'relu'))\n",
        "model.add(layers.Dropout(0.3))\n",
        "\n",
        "model.add(layers.Dense(32, activation = 'relu'))\n",
        "model.add(layers.Dropout(0.3))\n",
        "\n",
        "model.add(layers.Dense(1, activation = 'sigmoid'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-Qa4RX7hZfS",
        "outputId": "e8e78b6e-8d4f-41cc-e073-b3e9ad7f234f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling the model\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "4rLe9KoUiULg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "history = model.fit(X_train, y_train, epochs = 20,  batch_size = 4, validation_split = 0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uB8Yjx1Rifg2",
        "outputId": "9092a309-cf8b-4cff-a735-2e457225679c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 210ms/step - accuracy: 0.6429 - loss: 0.6258 - val_accuracy: 0.0000e+00 - val_loss: 0.7761\n",
            "Epoch 2/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7262 - loss: 0.6006 - val_accuracy: 0.0000e+00 - val_loss: 0.8143\n",
            "Epoch 3/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5476 - loss: 0.6363 - val_accuracy: 0.0000e+00 - val_loss: 0.8544\n",
            "Epoch 4/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7262 - loss: 0.5127 - val_accuracy: 0.0000e+00 - val_loss: 0.9039\n",
            "Epoch 5/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5476 - loss: 0.6206 - val_accuracy: 0.0000e+00 - val_loss: 0.9503\n",
            "Epoch 6/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7262 - loss: 0.6422 - val_accuracy: 0.0000e+00 - val_loss: 1.0034\n",
            "Epoch 7/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8214 - loss: 0.5522 - val_accuracy: 0.0000e+00 - val_loss: 1.0525\n",
            "Epoch 8/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7262 - loss: 0.4440 - val_accuracy: 0.0000e+00 - val_loss: 1.1045\n",
            "Epoch 9/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6429 - loss: 0.5980 - val_accuracy: 0.0000e+00 - val_loss: 1.1483\n",
            "Epoch 10/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7262 - loss: 0.4602 - val_accuracy: 0.0000e+00 - val_loss: 1.1986\n",
            "Epoch 11/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7262 - loss: 0.5778 - val_accuracy: 0.0000e+00 - val_loss: 1.2368\n",
            "Epoch 12/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6429 - loss: 0.5136 - val_accuracy: 0.0000e+00 - val_loss: 1.2709\n",
            "Epoch 13/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7262 - loss: 0.3753 - val_accuracy: 0.0000e+00 - val_loss: 1.3078\n",
            "Epoch 14/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7262 - loss: 0.5182 - val_accuracy: 0.0000e+00 - val_loss: 1.3339\n",
            "Epoch 15/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7262 - loss: 0.4205 - val_accuracy: 0.0000e+00 - val_loss: 1.3668\n",
            "Epoch 16/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6429 - loss: 0.5244 - val_accuracy: 0.0000e+00 - val_loss: 1.3930\n",
            "Epoch 17/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7262 - loss: 0.5073 - val_accuracy: 0.0000e+00 - val_loss: 1.4242\n",
            "Epoch 18/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7262 - loss: 0.6047 - val_accuracy: 0.0000e+00 - val_loss: 1.4353\n",
            "Epoch 19/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9048 - loss: 0.4521 - val_accuracy: 0.0000e+00 - val_loss: 1.4372\n",
            "Epoch 20/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6429 - loss: 0.4837 - val_accuracy: 0.0000e+00 - val_loss: 1.4216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PERUWbWGis_i",
        "outputId": "3b2a27dc-b85c-42a6-b7eb-1a6cea466cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 0s - 33ms/step - accuracy: 0.0000e+00 - loss: 1.9156\n",
            "Test accuracy: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_jobs_for_user(user_id, top_n=3):\n",
        "    user_profile = user_profiles[user_id - 1]\n",
        "\n",
        "    # Prepare input data for prediction\n",
        "    job_recommendations = []\n",
        "    for job_id in range(101, 106):\n",
        "        job_profile = job_profiles[job_id - 101]\n",
        "        input_features = np.concatenate((user_profile, job_profile)).reshape(1, -1)\n",
        "\n",
        "        # Predict application likelihood\n",
        "        prediction = model.predict(input_features)[0][0]\n",
        "        job_recommendations.append((job_id, prediction))\n",
        "\n",
        "    # Sort and recommend top N jobs\n",
        "    job_recommendations.sort(key=lambda x: x[1], reverse=True)\n",
        "    recommended_jobs = [job_id for job_id, _ in job_recommendations[:top_n]]\n",
        "\n",
        "    print(f\"Recommended Jobs for User {user_id}:\")\n",
        "    for job_id in recommended_jobs:\n",
        "        job_title = jobs_df[jobs_df['job_id'] == job_id]['title'].values[0]\n",
        "        print(f\"Job ID: {job_id}, Title: {job_title}\")\n",
        "\n",
        "# recommendation for user 1\n",
        "recommend_jobs_for_user(user_id=1, top_n=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQJPVgbWi10k",
        "outputId": "9a808914-ae07-4ed7-fc91-ffeffc61f1d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Recommended Jobs for User 1:\n",
            "Job ID: 105, Title: AWS Architect\n",
            "Job ID: 101, Title: Data Scientist\n",
            "Job ID: 103, Title: Frontend Engineer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Calculate cosine similarity between users\n",
        "user_similarities = cosine_similarity(user_profiles)\n",
        "\n",
        "# Function to recommend connections\n",
        "def recommend_connections_for_user(user_id, top_n=3):\n",
        "    user_idx = user_id - 1\n",
        "    similarities = user_similarities[user_idx]\n",
        "\n",
        "    # Sort and recommend top N connections (excluding self)\n",
        "    similar_users = np.argsort(similarities)[::-1][1:top_n+1]\n",
        "\n",
        "    print(f\"Recommended Connections for User {user_id}:\")\n",
        "    for idx in similar_users:\n",
        "        similar_user_id = idx + 1\n",
        "        similar_user_name = users_df[users_df['user_id'] == similar_user_id]['name'].values[0]\n",
        "        print(f\"User ID: {similar_user_id}, Name: {similar_user_name}\")\n",
        "\n",
        "# Example recommendation for user 1\n",
        "recommend_connections_for_user(user_id=1, top_n=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3bBkVPAjeN9",
        "outputId": "e60728b3-1a32-46b7-894b-9322eb289b9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommended Connections for User 1:\n",
            "User ID: 4, Name: David\n",
            "User ID: 2, Name: Bob\n",
            "User ID: 3, Name: Charlie\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def linkedin_recommendations(user_id, top_n_jobs=3, top_n_connections=3):\n",
        "    print(f\"Recommendations for User {user_id}:\")\n",
        "    recommend_jobs_for_user(user_id, top_n_jobs)\n",
        "    recommend_connections_for_user(user_id, top_n_connections)\n",
        "\n",
        "# Example recommendation for user 1\n",
        "linkedin_recommendations(user_id=1, top_n_jobs=3, top_n_connections=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69CSpffpjhz8",
        "outputId": "ccca8b11-eb30-41e7-893c-12a17ee0e3d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for User 1:\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Recommended Jobs for User 1:\n",
            "Job ID: 105, Title: AWS Architect\n",
            "Job ID: 101, Title: Data Scientist\n",
            "Job ID: 103, Title: Frontend Engineer\n",
            "Recommended Connections for User 1:\n",
            "User ID: 4, Name: David\n",
            "User ID: 2, Name: Bob\n",
            "User ID: 3, Name: Charlie\n"
          ]
        }
      ]
    }
  ]
}